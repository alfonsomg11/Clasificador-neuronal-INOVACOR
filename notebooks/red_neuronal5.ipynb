{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from itertools import permutations \n",
    "\n",
    "resultados = np.zeros((3912,10))\n",
    "\n",
    "def save_model(network):\n",
    "    \n",
    "    model_json = network.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    network.save_weights(\"model.h5\")\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = models.model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    return loaded_model\n",
    "\n",
    "def combine(units,number_of_layers):\n",
    "    \n",
    "    mixed_vals = [item for t in list(permutations(units,number_of_layers)) for item in t]\n",
    "    return mixed_vals\n",
    "\n",
    "def maximum_model_efficiency(history_dict):\n",
    "    \n",
    "    validation_accuracy_values = np.zeros(repeticiones)\n",
    "    c=0\n",
    "    for i in history_dict['val_accuracy']:\n",
    "        \n",
    "        if c < (repeticiones):\n",
    "            \n",
    "            validation_accuracy_values[c] = i\n",
    "            c+=1\n",
    "            \n",
    "    val_acc_max = np.amax(validation_accuracy_values)\n",
    "    index = np.where(validation_accuracy_values == val_acc_max)\n",
    "    maximum_eff = index[0] + 1\n",
    "    \n",
    "def net_build(units,number_of_layers,activation_func,iterations):\n",
    "    \n",
    "    row = 0\n",
    "    \n",
    "    for h in range (len(activation_func)):\n",
    "        \n",
    "        for i in range (len(number_of_layers)):\n",
    "\n",
    "            a = combine(units,number_of_layers[i])\n",
    "\n",
    "            cardboard_f = pd.read_excel(\"cardboard.xlsx\", header=None)\n",
    "            cardboard_f = cardboard_f.to_numpy()\n",
    "            np.random.shuffle(cardboard_f)\n",
    "\n",
    "            cardboard_f_train = cardboard_f[:900,:10]\n",
    "            cardboard_f_test = cardboard_f[900:,:10]\n",
    "\n",
    "            train_labels = cardboard_f[:900,10]\n",
    "            test_labels = cardboard_f[900:,10]\n",
    "\n",
    "            len(train_labels)\n",
    "            train_labels = train_labels.astype(int)\n",
    "\n",
    "            len(test_labels)\n",
    "            test_labels = test_labels.astype(int)\n",
    "\n",
    "            train_labels = to_categorical(train_labels)\n",
    "            network = models.Sequential()\n",
    "\n",
    "            var_ns = ''\n",
    "\n",
    "            for j in range (len(a)):\n",
    "\n",
    "                network.add(layers.Dense(a[j], activation=activation_func[h], input_shape=(10,)))\n",
    "\n",
    "                var_ns = var_ns + str(a[j])\n",
    "\n",
    "                if((j+1)%number_of_layers[i] == 0):\n",
    "\n",
    "                    network.add(layers.Dense(2, activation='softmax'))\n",
    "                    network.compile(optimizer='rmsprop',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "                    x_val = cardboard_f_train[:450]\n",
    "                    partial_x_train = cardboard_f_train[450:]\n",
    "\n",
    "                    y_val = train_labels[:450]\n",
    "                    partial_y_train = train_labels[450:]\n",
    "\n",
    "                    history = network.fit(partial_x_train,\n",
    "                                        partial_y_train,\n",
    "                                        epochs=repeticiones,\n",
    "                                        batch_size=128,\n",
    "                                        validation_data=(x_val, y_val),\n",
    "                                        verbose=0)\n",
    "\n",
    "                    history_dict = history.history\n",
    "                    prediction_vector=network.predict(cardboard_f_test)\n",
    "\n",
    "                    type_zero_count = 0\n",
    "                    type_one_count = 0\n",
    "                    guesses = np.ones(len(prediction_vector))\n",
    "\n",
    "                    for j in range (len(prediction_vector)):\n",
    "                        if prediction_vector[j,0] > prediction_vector[j,1]:\n",
    "                            type_zero_count += 1\n",
    "                            guesses[j] = 0\n",
    "                        else:\n",
    "                            type_one_count += 1\n",
    "                            guesses[j] = 1\n",
    "\n",
    "                    hits = 0\n",
    "                    for k in range (len(guesses)):    \n",
    "                        if guesses[k] == test_labels[k]:\n",
    "                            hits += 1\n",
    "\n",
    "                    non_hits = len(guesses) - hits\n",
    "                    efficiency = float(\"{:0.2f}\".format(hits/len(guesses)*100))\n",
    "\n",
    "                    validation_accuracy_values=np.zeros(repeticiones)\n",
    "                    c=0\n",
    "                    for m in history_dict['val_accuracy']:\n",
    "\n",
    "                        if c < (repeticiones):\n",
    "\n",
    "                            validation_accuracy_values[c] = m\n",
    "                            c+=1\n",
    "\n",
    "                    val_acc_max = np.amax(validation_accuracy_values)\n",
    "                    index = np.where(validation_accuracy_values == val_acc_max)[0].tolist()[0]\n",
    "\n",
    "                    resultados[row,0] = type_zero_count\n",
    "                    resultados[row,1] = type_one_count\n",
    "                    resultados[row,2] = hits\n",
    "                    resultados[row,3] = non_hits\n",
    "                    resultados[row,4] = efficiency\n",
    "                    resultados[row,5] = float(\"{:0.2f}\".format(np.amax(validation_accuracy_values)*100))\n",
    "                    resultados[row,6] = index\n",
    "                    resultados[row,7] = number_of_layers[i]\n",
    "                    resultados[row,8] = int(var_ns)\n",
    "                    resultados[row,9] = h + 1\n",
    "                    var_ns = ''\n",
    "                    row += 1\n",
    "                    \n",
    "                    if (efficiency > 92.7):\n",
    "                        save_model(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unidades_vals = [30,60,90,110]\n",
    "num_capas=[1,2,3]\n",
    "f_activacion = ['relu']\n",
    "repeticiones=750\n",
    "\n",
    "net_build(unidades_vals,num_capas,f_activacion,repeticiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type A cardboard</th>\n",
       "      <th>Type B cardboard</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Non-hits</th>\n",
       "      <th>Test Accuracy (%)</th>\n",
       "      <th>Max validation accuracy (%)</th>\n",
       "      <th>Max accuracy epoch number</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Number of neurons</th>\n",
       "      <th>Activation function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>485.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>93.33</td>\n",
       "      <td>92.89</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9030.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>484.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>92.44</td>\n",
       "      <td>515.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6030.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>454.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>92.33</td>\n",
       "      <td>93.11</td>\n",
       "      <td>311.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9060.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>513.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>92.22</td>\n",
       "      <td>91.78</td>\n",
       "      <td>542.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30110.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>443.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>92.22</td>\n",
       "      <td>92.89</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60110.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>458.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>92.11</td>\n",
       "      <td>94.44</td>\n",
       "      <td>444.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3011060.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>469.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>91.78</td>\n",
       "      <td>94.00</td>\n",
       "      <td>603.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3060110.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>449.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>91.56</td>\n",
       "      <td>92.67</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6090.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>430.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>94.44</td>\n",
       "      <td>514.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3011090.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>439.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>90.44</td>\n",
       "      <td>94.22</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3090110.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>471.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>93.11</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90110.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>469.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>89.78</td>\n",
       "      <td>93.56</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11030.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>430.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>89.67</td>\n",
       "      <td>91.11</td>\n",
       "      <td>481.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>483.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88.89</td>\n",
       "      <td>89.56</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3011090.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>480.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>88.78</td>\n",
       "      <td>89.56</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3011060.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>457.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>789.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>87.67</td>\n",
       "      <td>87.78</td>\n",
       "      <td>664.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>517.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>86.22</td>\n",
       "      <td>710.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>543.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>86.78</td>\n",
       "      <td>86.89</td>\n",
       "      <td>703.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>86.56</td>\n",
       "      <td>88.89</td>\n",
       "      <td>745.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3060.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>551.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>86.44</td>\n",
       "      <td>88.67</td>\n",
       "      <td>283.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>309060.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Type A cardboard  Type B cardboard   Hits  Non-hits  Test Accuracy (%)  \\\n",
       "10             485.0             415.0  840.0      60.0              93.33   \n",
       "7              484.0             416.0  837.0      63.0              93.00   \n",
       "11             454.0             446.0  831.0      69.0              92.33   \n",
       "6              513.0             387.0  830.0      70.0              92.22   \n",
       "9              443.0             457.0  830.0      70.0              92.22   \n",
       "20             458.0             442.0  829.0      71.0              92.11   \n",
       "17             469.0             431.0  826.0      74.0              91.78   \n",
       "8              449.0             451.0  824.0      76.0              91.56   \n",
       "21             430.0             470.0  819.0      81.0              91.00   \n",
       "19             439.0             461.0  814.0      86.0              90.44   \n",
       "12             471.0             429.0  810.0      90.0              90.00   \n",
       "13             469.0             431.0  808.0      92.0              89.78   \n",
       "5              430.0             470.0  807.0      93.0              89.67   \n",
       "61             483.0             417.0  800.0     100.0              88.89   \n",
       "60             480.0             420.0  799.0     101.0              88.78   \n",
       "43             457.0             443.0  789.0     111.0              87.67   \n",
       "41             517.0             383.0  783.0     117.0              87.00   \n",
       "42             543.0             357.0  781.0     119.0              86.78   \n",
       "4              520.0             380.0  779.0     121.0              86.56   \n",
       "58             551.0             349.0  778.0     122.0              86.44   \n",
       "\n",
       "    Max validation accuracy (%)  Max accuracy epoch number  Number of layers  \\\n",
       "10                        92.89                       65.0               2.0   \n",
       "7                         92.44                      515.0               2.0   \n",
       "11                        93.11                      311.0               2.0   \n",
       "6                         91.78                      542.0               2.0   \n",
       "9                         92.89                      339.0               2.0   \n",
       "20                        94.44                      444.0               3.0   \n",
       "17                        94.00                      603.0               3.0   \n",
       "8                         92.67                      558.0               2.0   \n",
       "21                        94.44                      514.0               3.0   \n",
       "19                        94.22                      163.0               3.0   \n",
       "12                        93.11                       47.0               2.0   \n",
       "13                        93.56                      133.0               2.0   \n",
       "5                         91.11                      481.0               2.0   \n",
       "61                        89.56                      114.0               3.0   \n",
       "60                        89.56                      102.0               3.0   \n",
       "43                        87.78                      664.0               1.0   \n",
       "41                        86.22                      710.0               1.0   \n",
       "42                        86.89                      703.0               1.0   \n",
       "4                         88.89                      745.0               2.0   \n",
       "58                        88.67                      283.0               3.0   \n",
       "\n",
       "    Number of neurons  Activation function  \n",
       "10             9030.0                  1.0  \n",
       "7              6030.0                  1.0  \n",
       "11             9060.0                  1.0  \n",
       "6             30110.0                  1.0  \n",
       "9             60110.0                  1.0  \n",
       "20          3011060.0                  1.0  \n",
       "17          3060110.0                  1.0  \n",
       "8              6090.0                  1.0  \n",
       "21          3011090.0                  1.0  \n",
       "19          3090110.0                  1.0  \n",
       "12            90110.0                  1.0  \n",
       "13            11030.0                  1.0  \n",
       "5              3090.0                  1.0  \n",
       "61          3011090.0                  2.0  \n",
       "60          3011060.0                  2.0  \n",
       "43              110.0                  2.0  \n",
       "41               60.0                  2.0  \n",
       "42               90.0                  2.0  \n",
       "4              3060.0                  1.0  \n",
       "58           309060.0                  2.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_dataFrame=pd.DataFrame(resultados,columns=['Type A cardboard','Type B cardboard','Hits'\n",
    "                                                      ,'Non-hits','Test Accuracy (%)','Max validation accuracy (%)'\n",
    "                                                      ,'Max accuracy epoch number','Number of layers'\n",
    "                                                      ,'Number of neurons'\n",
    "                                                      ,'Activation function'])\n",
    "\n",
    "resultados_dataFrame.nlargest(20,['Test Accuracy (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
